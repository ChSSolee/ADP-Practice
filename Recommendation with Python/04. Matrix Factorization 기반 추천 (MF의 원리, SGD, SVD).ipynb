{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9156133",
   "metadata": {},
   "source": [
    "# 04. Matrix Factorization 기반 추천\n",
    "\n",
    "- 추천을 위한 알고리즘은 크게 메모리 기반 (memory-based)과 모델 기반 (model- based)로 구분\n",
    "- **메모리 기반 알고리즘은 추천을 위한 데이터를 모두 메모리에 가지고 있으면서 추천이 필요할 때마다, 이 데이터를 사용해서 계산하는 방식으로 추천 (CF)**\n",
    "    - 메모리 기반 추천은 모든 데이터를 메로리에 저장하고 있기 때문에 원래 데이터를 충실하게 사용하는 장점이 있지만,    \n",
    "        \n",
    "        대량의 데이터를 다뤄야 하는 상용 사이트에서는 계산시간이 너무 오래 걸린다는 단점이 존재\n",
    "    \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- **모델 기반 추천은 데이터로부터 추천을 위한 모델을 구성한 후에 이 모델만 저장하고, 실제 추천을 할 때에는 이 모델을 사용해서 추천 (행렬 요인화, MF)**\n",
    "    - 모델 기반 추천 방식은 원래 데이터는 모형을 만드는 데만 사용하고, 일단 모델이 만들어지면 원래 데이터는 사용하지 않기 때문에 대규모 상용 사이트에서 필요한 빠른 반응이 가능하지만, \n",
    "        \n",
    "        모델이 만들어지는 과정에서 많은 계싼이 필요\n",
    "\n",
    "<br>\n",
    "\n",
    "- **메모리 기반 추천은 개별 사용자의 데이터에 집중하는 데 비해, 모델 기반 추천은 전체 사용자의 평가 패턴으로부터 모델을 구성하기 때문에,**\n",
    "    \n",
    "    **데이터가 가지고 있는 약한 신호(weak signal)도 더 잘 잡아내는 장점이 존재**\n",
    "    \n",
    "    - **약한 신호 : 개별 사용자의 행동분석에는 잘 드러나지 않는 패턴**\n",
    "    \n",
    "        (소수의 사용자가 소수의 영화에 대해서만 특정한 평가 패턴이 있는 경우, 개별 사용자나 개별 아이템에 집중하는 메모리 기반 알고리즘은 이것을 잡아내기 쉽지 않지만, \n",
    "        \n",
    "        전체 데이터를 대상으로 모델을 구성하는 모델 기반 추천은 더 잘 잡아냄)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf721003",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 04.01. Matrix Factorization(MF) 방식의 원리\n",
    "- 행렬요인화 (Matrix Factorization :MF)는 평가 데이터, 즉 (사용자 X 아이템)으로 구성된 하나의 행렬을 2개의 행렬로 분해\n",
    "\n",
    "<img src='https://blog.kakaocdn.net/dn/c56IN5/btrqMR4mzQk/eTTwJLK93xJeYGFndTbRY1/img.png' width='800px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ce818",
   "metadata": {},
   "source": [
    "- **$R$ : (사용자 X 아이템) 평가 데이터이며, M명의 사용자가 N개의 아이템에 대해 평가한 데이터를 포함하고 있는 2차원 행렬**\n",
    "    - **행렬의 각 원소 (element)는 해당 사용자의 해당 아이템에 대한 평가정보**\n",
    "    - 이 행렬은 사용자가 실제로 평가한 아이템에 대한 평점만을 가지고 있기에, 결측값의 빈도가 높음\n",
    "\n",
    "<br>\n",
    "\n",
    "- **$R$행렬을 사용자행렬 $P$와 아이템행렬 $Q$로 쪼개어 분석하는 것이 MF방식**\n",
    "- **$P$는 $M\\times K$의 차원을 가지고, $Q$는 $N\\times K$개의 차원을 가짐**\n",
    "    \n",
    "    $\\rightarrow$ $P \\times Q^T$인 $\\hat{R}$은 $M\\times N$의 차원을 가지게 되어, $R$과 같은 크기의 행렬이 됨\n",
    "    \n",
    "    $\\rightarrow$ **$\\hat{R}$은 $R$의 예측치이며, $\\hat{R}$이 최대한 R에 가까운 값을 가지도록 하는 $P$와 $Q$를 구하는 모델을 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7c21a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **$P$는 각 사용자의 특성을 나타내는 $K$개 요인의 값으로 이루어진 행렬,**\n",
    "\n",
    "    **$Q$는 각 아이템의 특성을 나타내는 $K$개의 요인의 값으로 이루어진 행렬**\n",
    "- **$P$와 $Q$행렬에서 공통인 $K$개의 요인이 존재하며, 이는 잠재요인 (latent factor)**\n",
    "\n",
    "    $\\rightarrow$ **즉, MF는 사용자와 아이템의 특성을 $K$개의 잠재요인을 사용해서 분석하는 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96be4d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### $K=2$ (잠재요인이 2개)인 예시\n",
    "- $K=2$이므로, 사용자와 영화의 특성을 두 개 요인으로 나타낼 수 있음\n",
    "- 만일 두 요인의 차원이 (액션-드라마), (판타지-사실주의)이며, \n",
    "    \n",
    "   모든 사용자와 영화의 특성은 각 요인에 대해서 -1.0 ~ 1.0의 값으로 표현할 수 있다고 가정할 때,\n",
    "   \n",
    "   4가지 사용자에 대한 두 가지 잠재요인의 값 $P$행렬\n",
    "   \n",
    "   - 첫 번째 요인 (액션-드라마)에서 -1에 가까울수록 액션의 성격이 강하고, 1에 가까울수록 드라마의 성격이 강함\n",
    "   - 두 번째 요인 (판타지-사실주의)에서 -1에 가까울수록 판타지 성격이 강하고, 1에 가까울수록 사실주의 성격이 강함\n",
    "   \n",
    "| 사용자 | 액션- 드라마  | 판타지-사실주의 |\n",
    "| - | - | - |\n",
    "| a | -0.43 | 0.21 |\n",
    "| b | 0.31 | 0.92|\n",
    "| c | 0.69 | -0.03 |\n",
    "| d | 0.46 | -0.30 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a504291",
   "metadata": {},
   "source": [
    "- a는 잠재요인 1이 -0.43으로서 액션영화를 좋아하지만, 잠재요인 2는 0.21로서 판타지보다는 사실적인 영화를 좋아함\n",
    "\n",
    "<br>\n",
    "\n",
    "- 영화별 잠재요인에 대한 $Q$행렬\n",
    "    \n",
    "    - ㄱ는 드라마의 성격이 강하고, 사실주의 성향이 강함\n",
    "\n",
    "| 영화 | 액션- 드라마  | 판타지-사실주의 |\n",
    "| - | - | - |\n",
    "| ㄱ | 0.31 | 0.60 |\n",
    "| ㄴ | 0.61 | -0.82|\n",
    "| ㄷ | -0.38 | -0.61 |\n",
    "| ㄹ | -0.79 | 0.08 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee338ea",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 2가지 요인의 값에 따라 2차원 공간에 배치해보면, 어떤 사용자가 어떤 영화를 좋아할지를 알 수 있음\n",
    "    - r는 a의 취향에 잘 맞을 것이고, d는 4개의 영화 중에는 ㄴ를 가장 선호할 것이라 추측\n",
    "    \n",
    "    $\\rightarrow$ **즉, 영화의 특성과 사용자의 특성이 각각 2개의 잠재요인으로 분해되었고, 이 잠재요인을 보면 어떤 영화가 어떤 사요자 취향에 맞을지 예상 가능**\n",
    "    \n",
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FARQPW%2FbtrqLwNKIji%2FpWOkaxzZ7dLIDSyYx4Z780%2Fimg.png' width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c48604",
   "metadata": {},
   "source": [
    "- MF의 원리를 사용하면,ㄱ ㅏㄱ 사용자의 각 영화에 대한 예상 평점 $\\hat{R}$도 알 수 있음\n",
    "\n",
    "    $\\rightarrow$ $\\hat{R}=P \\times Q^T$이므로, $P$와 $Q$를 사용해서 $\\hat{R}$를 계산가능\n",
    "    \n",
    "| 사용자\\\\영화 | ㄱ  | ㄴ | ㄷ| ㄹ |\n",
    "| - | - | - | - | - |  \n",
    "| a | -0.0073 | -0.4345 | 0.0353 | 0.3565 |\n",
    "| b | 0.6481 | -0.5653 | -0.6790 | -0.1713 |\n",
    "| c | 0.1959 | 0.4455 | -0.2439 | -0.5475 |\n",
    "| d | -0.0374 | 0.5266 | 0.0082 | -0.3874 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6025e5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 04.02. SGD (Stochastic Gradient Descent)를 사용한 MF\n",
    "- 어떤 도메인에 대해서 사용자와 아이템의 특성을 잘 설명할 수 있는 $K$개의 요인이 존재하고,\n",
    "    \n",
    "    각 사용자와 아이템의 $K$개의 요인에 대한 측정값을 알 수 있다면,  모든 사용자의 모든 아이템에 대한 예측 평점을 계산할 수 있음\n",
    "    \n",
    "- 만일 사용자가 어떤 영화에 대해서 실제 평점을 부여하였다면, 그 실제 평점과 예상 평점의 차이로 정확도를 계산\n",
    "\n",
    "- **MF의 핵심은 주어진 사용자, 아이템의 관계를 가장 잘 설명하는 $P$, $Q$행렬을 분해하는 것**\n",
    "    - 주어진 (사용자 X 아이템)의 평점행렬인 $R$로부터 $P$와 $Q$를 분해하는 알고리즘의 순서\n",
    "    \n",
    "    1. **잠재요인의 개수인 $K$를 설정, $K$는 경험에 의해 직관적으로 정해도 되고, 다양한 $K$를 비교하면서 최적의 수를 정함**\n",
    "    2. **주어진 $K$에 따라 $P(M\\times K)$와 $Q(N\\times K)$행렬을 만들고 초기화**  (**맨 처음에는 $P$, $Q$행렬을 임의의 수로 채우는 것이 보통**)\n",
    "        \n",
    "    3. **주어진 $P$, $Q$행렬을 사용해서 예측 평점 $\\hat{R}(=P \\times Q^T)$를 계산**\n",
    "    4. **$R$에 있는 실제 평점에 대해서 예측 평점 $\\hat{R}$의 예측과 비교해서 오차를 구하고, 이 오차를 줄이기 위해서 $P$, $Q$값을 수정**\n",
    "    5. **전체 오차가 미리 정해진 기준값 이하가 되거나, 미리 정해진 반복 횟수에 도달할 때 까지 반복**\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - **핵심은 4에서 예측 오차를 줄이기 위해서 $P$ ,$Q$를 수정하는 방식이며, 가장 일반적으로 사용하는 방법은 SGD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ebaf8c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fx5OBI%2FbtrqMFbY5eA%2FAN0gpSqLPpqGW1hwKiCMMk%2Fimg.png' width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6e525",
   "metadata": {},
   "source": [
    "- 예측값 $\\hat{R}$은 $P \\times Q^T$이므로, 사용자 $i$의 아이템 $j$에 대한 예측값 $\\hat{r}_{i,j}$는 \n",
    "\n",
    "    $$\\hat{r}_{i,j} = p^T_i q_j = \\sum^K_{k=1} p_{ik} q_{kj}$$\n",
    "    \n",
    "- 에측 오차 $\\epsilon_{ij}$와 오차 제곱은\n",
    "\n",
    "    $$\\epsilon_{ij} = (r_{ij} - \\hat{r}_{ij})$$\n",
    "    \n",
    "    $$\\epsilon^2_{i,j} = (r_{ij} - \\hat{r}_{ij})^2 = (r_{ij} - \\sum^K_{k=1}p_{ik}q_{kj})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db26a47",
   "metadata": {},
   "source": [
    "- SGD에 따라 오차제곱을 최소화하는 방향을 탐색하기 위해, 오차 제곱을 $p$와 $q$에 대해서 편미분\n",
    "\n",
    "    $$\\frac{\\delta}{\\delta p_{ik}}e_{ij} = -2 (r_{ij} -\\hat{r}_{ij})(q_{kj})=-2 e_{ij} q_{kj}$$\n",
    "    \n",
    "    $$\\frac{\\delta}{\\delta q_{ik}}e_{ij} = -2 (r_{ij} -\\hat{r}_{ij})(p_{ik})=-2 e_{ij} p_{ik}$$\n",
    "    \n",
    "    따라서 오차를 줄여주는 새로운 $p_i$, $q_j$값인 $p^{'}_i$와 $q^{'}_j$를 구하기 위한 식\n",
    "    \n",
    "    $$p^{'}_i=p_{ik} - \\alpha \\frac{\\delta}{\\delta p^2_{ik}} = p_{ik} + 2\\alpha e_{ij} q_{kj}$$\n",
    "    \n",
    "    $$q^{'}_i=q_{kj} - \\alpha \\frac{\\delta}{\\delta q^2_{kj}} = q_{kj} + 2\\alpha e_{ij} p_{ik}$$\n",
    "    \n",
    "    - $\\alpha$는 학습률 (learning rate)\n",
    "\n",
    "\n",
    "- 연산을 반복할 때 마다 실제 평점이 존재하는 모든 $(p_i, q_j)$조합에 대해 예측값과 오차를 계산한 후에 위의 식에 따라$p_i$, $q_j$ 값을 갱신\n",
    "    \n",
    "    $\\rightarrow$ 오차가 점차 감소하며 $P$와 $Q$행렬을 추정\n",
    "\n",
    "<br>\n",
    "\n",
    "### 과적합 (over-fitting)과 정규화 (regularization)\n",
    "- **과적합을 방지하기 위하여 오차제곱에 정규화 항을 추가**\n",
    "\n",
    "    $$\\epsilon^2_{i,j} = (r_{ij} - \\sum^K_{k=1}p_{ik}q_{kj})^2 + \\frac{\\beta}{2} \\sum^K_{k=1}(||P||^2 + ||Q||^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f286f5d",
   "metadata": {},
   "source": [
    "- $p_i$, $q_j$에 대해서 편미분\n",
    "    - $\\beta$는 정규화 정도를 정하는 정규화 계수\n",
    "    \n",
    "    $$p^{'}_i=p_{ik} - \\alpha \\frac{\\delta}{\\delta p^2_{ik}} = p_{ik} + \\alpha (2e_{ij} q_{kj} - \\beta p_{ik})$$\n",
    "    \n",
    "    $$p^{'}_i=q_{kj} - \\alpha \\frac{\\delta}{\\delta q^2_{kj}} = q_{kj} + \\alpha (2e_{ij} p_{ik} - \\beta q_{kj})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe1d70",
   "metadata": {},
   "source": [
    "- **각 사용자와 각 아이템의 편향 (경향성, bias)고려**\n",
    "    - **CF알고리즘과 마찬가지로, 각 사용자와 각 아이템은 일정한 편향(평가가 높거나 낮은 경향)이 존재**\n",
    "    \n",
    "        $\\rightarrow$ 편향을 제거하고 나머지 데이터만을 분석하는 것이 더 정확\n",
    "        \n",
    "    <br>\n",
    "    \n",
    "    - **$b$는 $R$의 전체 평균, 데이터가 주어지면 하나의 값으로 결정**\n",
    "    - **$b u_i$는 전체 평균을 제거한 후, 사용자 $i$의 평가경향 (사용자 $i$의 평균과 전체 평균의 차이)**\n",
    "    - **$bd_j$는 전체 평균을 제거한 후 아이템 $j$의 평가경향 (아이템 $j$의 평균과 전체 평균의 차이)**\n",
    "    \n",
    "    $$\\hat{r}_{ij} = b + b u_i + bd_j + \\sum^K_{k=1} p_{ik}q_{kj}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "- **CF알고리즘에서는 사용자와 아이템별로 평가경향이 한 번에 계산되었지만, MF에서는 계산할 때마다 오차를 최소화하도록 평가 경향을 다시 조정**\n",
    "\n",
    "    $\\rightarrow$ 편향을 고려하며 편미분과정을 거친 새로운 $bu_i$와 $bd_j$\n",
    "    \n",
    "    $$bu^{'}_i = bu_i + \\alpha (e_{ij}-\\beta b u_i)$$\n",
    "    \n",
    "    $$bd^{'}_j = bd_j + \\alpha (e_{ij}-\\beta b d_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c828a60",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "- **정규화와 편향을 고려하며 SGD를 사용한 계산을 여러번 반복**\n",
    "    - **최초의 상태에서, $R$행렬에서 원소가 존재하는(사용자가 평가를 한) 모든 (사용자 $i$, 아이템 $j$) 조합에 대해서**\n",
    "        \n",
    "        **$P$ ,$Q$ 행렬과 $bu$, $bd$를 갱신하는 것이 한번의 계산**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e71683",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 04.03. SGD를 사용한 MF 기본 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "828a986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0391ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb458b68",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `K` : 잠재요인의 수\n",
    "- `alpha` : 학습률 $\\alpha$\n",
    "- `beta` : 정규화 계수 $\\beta$\n",
    "- `iterations` : SGD 계산 반복 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa18190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "    \n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    # RMSE 계산 함수\n",
    "    def rmse(self):\n",
    "        \n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "            \n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        \n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "    \n",
    "    # 데이터 학습\n",
    "    def train(self): \n",
    "        # P행렬과 Q행렬의 초기값을, 평균이 0이고 표준편차가 1/K인 정규분포 난수로 생성\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # 사용자 평가 편향 bu와, 아이템 평가 편향 bd의 초기값을 0으로 생성\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        # 전체평균 b 계산\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # R의 원소중 결측값이 아닌 원소와 그 인덱스를 리스트로 생성 -> SGD를 적용할 대상\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "        \n",
    "        # 시행\n",
    "        training_process = [] # 각 시행별 RMSE 저장 \n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1, rmse))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f \" % (i+1, rmse))\n",
    "                    \n",
    "        return training_process\n",
    "                    \n",
    "    # 각 시행마다 갱신된 bu, bd, P, Q를 통하여, R예측\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # SGD 적용 함수\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f316e",
   "metadata": {},
   "source": [
    "- 전체 데이터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63256067",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cd17884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                               ...   \n",
       "1          5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
       "2          4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n",
       "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5          4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "939        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n",
       "940        0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n",
       "941        5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n",
       "942        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "943        0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n",
       "\n",
       "movie_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user_id                                                               \n",
       "1          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "939        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "940        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "941        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "942        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "943        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d219c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9585 \n",
      "Iteration: 20 ; Train RMSE = 0.9374 \n",
      "Iteration: 30 ; Train RMSE = 0.9281 \n",
      "Iteration: 40 ; Train RMSE = 0.9226 \n",
      "Iteration: 50 ; Train RMSE = 0.9185 \n",
      "Iteration: 60 ; Train RMSE = 0.9147 \n",
      "Iteration: 70 ; Train RMSE = 0.9104 \n",
      "Iteration: 80 ; Train RMSE = 0.9046 \n",
      "Iteration: 90 ; Train RMSE = 0.8964 \n",
      "Iteration: 100 ; Train RMSE = 0.8852 \n"
     ]
    }
   ],
   "source": [
    "mf = MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
    "train_process = mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c173bc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 04.04 훈련/테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8a57d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "785c3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78944741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75000, 3), (25000, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train.shape, ratings_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1d201a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEW_MF():\n",
    "    \n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        \n",
    "        # user_id, item_id를 R의 인덱스와 매핑\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "            \n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)\n",
    "        \n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "            \n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "        \n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "            \n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        \n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # 테스트 데이터 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):     \n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0 # 훈련 데이터만을 사용하여 훈련을 진행하기에, 테스트 데이터에 해당 하는 R의 원소들은 제거 \n",
    "            \n",
    "        self.test_set = test_set\n",
    "        \n",
    "        return test_set                         \n",
    "\n",
    "    # 테스트 데이터 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "            \n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    # 훈련을 진행 하면서 테스트 데이터의 정확도를 계산\n",
    "    def test(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            \n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "                    \n",
    "        return training_process\n",
    "\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf07cc",
   "metadata": {},
   "source": [
    "- 훈련/테스트 데이터를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3064f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = NEW_MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5bc6d6",
   "metadata": {},
   "source": [
    "- $\\hat{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cce1ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.8481407  3.41301804 3.11753766 ... 3.33612259 3.49514425 3.44643964]\n",
      " [3.9132339  3.49335426 3.14594609 ... 3.43695812 3.55113494 3.53972662]\n",
      " [3.36057818 2.88199419 2.5693306  ... 2.81577634 2.93754147 2.93322341]\n",
      " ...\n",
      " [4.17355742 3.77803506 3.43328939 ... 3.70736355 3.84017079 3.82591872]\n",
      " [4.37121687 3.90902082 3.56549399 ... 3.83611    3.94313652 3.94382296]\n",
      " [3.79649597 3.36209539 3.01609241 ... 3.28803043 3.41394849 3.41406192]]\n"
     ]
    }
   ],
   "source": [
    "print(mf.full_prediction())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c233f6c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 04.05. MF의 최적 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e9c7e",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "#### 최적의 $K$값 탐색\n",
    "- 50 ~ 260의 범위에서의 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93e716e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cb00013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 50\n",
      "K = 60\n",
      "K = 70\n",
      "K = 80\n",
      "K = 90\n",
      "K = 100\n",
      "K = 110\n",
      "K = 120\n",
      "K = 130\n",
      "K = 140\n",
      "K = 150\n",
      "K = 160\n",
      "K = 170\n",
      "K = 180\n",
      "K = 190\n",
      "K = 200\n",
      "K = 210\n",
      "K = 220\n",
      "K = 230\n",
      "K = 240\n",
      "K = 250\n",
      "K = 260\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "index = []\n",
    "for K in range(50, 261, 10):\n",
    "    \n",
    "    print('K =', K)\n",
    "    R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "    mf = NEW_MF(R_temp, K=K, alpha=0.001, beta=0.02, iterations=100, verbose=False)\n",
    "    \n",
    "    test_set = mf.set_test(ratings_test)\n",
    "    result = mf.test()\n",
    "    index.append(K)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da7ee5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 최적의 반복횟수 (iteration) 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73e61ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "summary = []\n",
    "for i in tqdm(range(len(results))):\n",
    "    \n",
    "    RMSE = []\n",
    "    for result in results[i]:\n",
    "        RMSE.append(result[2])\n",
    "        \n",
    "    min = np.min(RMSE)\n",
    "    j = RMSE.index(min)\n",
    "    summary.append([index[i], j+1, RMSE[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1938372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 100, 0.94233764726906],\n",
       " [60, 100, 0.9430403144027483],\n",
       " [70, 100, 0.943521695335574],\n",
       " [80, 100, 0.9437372586198512],\n",
       " [90, 100, 0.9438034001428509],\n",
       " [100, 100, 0.9437054674594669],\n",
       " [110, 100, 0.9438279168356434],\n",
       " [120, 100, 0.9437603439993129],\n",
       " [130, 100, 0.9440474850055126],\n",
       " [140, 100, 0.9440045675351597],\n",
       " [150, 100, 0.9442191280129176],\n",
       " [160, 100, 0.9441649335133655],\n",
       " [170, 100, 0.9443158874483076],\n",
       " [180, 100, 0.9443137577924552],\n",
       " [190, 100, 0.9442941086782904],\n",
       " [200, 100, 0.9444329332017095],\n",
       " [210, 100, 0.9443483340489025],\n",
       " [220, 100, 0.944487549047772],\n",
       " [230, 100, 0.9444287589953927],\n",
       " [240, 100, 0.9445028066802735],\n",
       " [250, 100, 0.9444356498483899],\n",
       " [260, 100, 0.944577514561525]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2eae7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 하이퍼파라미터 탐색 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dd758d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "117a52bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(index, [x[2] for x in summary])\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a2b29d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 04.06. SVD와의 구분\n",
    "- **SVD는 데이터를 3개의 행렬로 분해하여 이를 학습시키고, 이 3개의 행렬로 원래의 행렬을 재현 (re-creation)하는 기법**\n",
    "- **MF는 원래 데이터를 $P(M\\times K)$, $Q(N\\times K)$, 2개의 행렬로 분해**\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='https://velog.velcdn.com/images/sangyun/post/c04c962d-0953-45d2-aa81-637258a5bc61/image.png' width='800px'>\n",
    "\n",
    "<br>\n",
    "\n",
    "- **SVD는 원래 행렬을 분해해서 3개의 행렬로 만든 다음, 이를 사용하여 원래 행렬을 재현하는 데에는 좋은 성능이지만,**\n",
    "    \n",
    "    **원래 행렬에 없는 값을 예측하는 데는 문제**\n",
    "    \n",
    "    - **SVD는 행령를 3개로 분해하다 보니, 원래 행렬에는 결측값을 허용하지 않기 때문**\n",
    "    \n",
    "        $\\rightarrow$ 영화 평점의 경우처럼, 사용자가 평가하지 않은 아이템에 대해서 결측값으로 표현할 수 없음\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - **만약 결측값 대신 0으로 대체하는 경우, 0을 하나의 값으로 인식하여, 이 값을 재현할 수 있도록 행렬을 분해**\n",
    "    \n",
    "        $\\rightarrow$ **을 재현한 결과에서 0이었던 원소는 모두 0에 가깝게 재현됨**\n",
    "        \n",
    "        $\\rightarrow$ **즉, 평가하지 않은 항목을 0으로 표시하고, 평가한 값만 가지고 학습시킨 후 0의 값을 다시 예측값으로 계산할 수가 없는 구조**\n",
    "\n",
    "    - SVD는 추천 시스템 분야에서는 거의 사용되지 않음\n",
    "\n",
    "<br>\n",
    "\n",
    "- **MF는 결측값을 0으로 표현했지만, SGD로 $P$, $Q$를 학습할 때에는 0인 값을 빼고 계산    $\\rightarrow$ 사실상 결측값은 제외하고 계산을 하는 구조**\n",
    "\n",
    "- **원래 $R$행렬에는 결측값이 있더라도, $P$, $Q$행렬은 결측값이 없이 학습되며,     학습이 끝나고 나면 $P$, $Q$를 사용해서 원래 행렬의 결측값도 정확히 예측**\n",
    "\n",
    "<br>\n",
    "\n",
    "- **MF와 SVD는 명백히 다른 분석기법이고, SVD는 추천 시스템분야에서는 거의 사용되지 않음**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
